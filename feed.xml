<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://hesamsheikh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hesamsheikh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-16T15:36:34+00:00</updated><id>https://hesamsheikh.github.io/feed.xml</id><title type="html">Hesam Sheikh</title><entry><title type="html">How I Stay Up to Date With the Latest AI Trends [2024]</title><link href="https://hesamsheikh.github.io/blog/2024/how-i-stay-up-to-date-with-the-latest-ai-trends-2024/" rel="alternate" type="text/html" title="How I Stay Up to Date With the Latest AI Trends [2024]"/><published>2024-08-15T14:01:45+00:00</published><updated>2024-08-15T14:01:45+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/how-i-stay-up-to-date-with-the-latest-ai-trends-2024</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/how-i-stay-up-to-date-with-the-latest-ai-trends-2024/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Stay ahead of the AI game with a concise list of resources&#x2026;Continue reading on Towards AI »]]></summary></entry><entry><title type="html">Create Synthetic Dataset Using Llama 3.1 to Fine-Tune Your LLM</title><link href="https://hesamsheikh.github.io/blog/2024/create-synthetic-dataset-using-llama-31-to-fine-tune-your-llm/" rel="alternate" type="text/html" title="Create Synthetic Dataset Using Llama 3.1 to Fine-Tune Your LLM"/><published>2024-08-07T09:41:38+00:00</published><updated>2024-08-07T09:41:38+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/create-synthetic-dataset-using-llama-31-to-fine-tune-your-llm</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/create-synthetic-dataset-using-llama-31-to-fine-tune-your-llm/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Using the giant Llama 3.1 405B and Nvidia Nemotron 4 reward model to create a synthetic dataset for instruction fine-tuning.Continue reading on Towards Data Science »]]></summary></entry><entry><title type="html">What We Still Don’t Understand About Machine Learning</title><link href="https://hesamsheikh.github.io/blog/2024/what-we-still-dont-understand-about-machine-learning/" rel="alternate" type="text/html" title="What We Still Don’t Understand About Machine Learning"/><published>2024-07-26T14:07:11+00:00</published><updated>2024-07-26T14:07:11+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/what-we-still-dont-understand-about-machine-learning</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/what-we-still-dont-understand-about-machine-learning/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Machine Learning unknowns that researchers struggle to understand&#x200A;&#x2014;&#x200A;from Batch Norm to what SGD hidesContinue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Learn Anything with AI and the Feynman Technique</title><link href="https://hesamsheikh.github.io/blog/2024/learn-anything-with-ai-and-the-feynman-technique/" rel="alternate" type="text/html" title="Learn Anything with AI and the Feynman Technique"/><published>2024-07-08T18:01:30+00:00</published><updated>2024-07-08T18:01:30+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/learn-anything-with-ai-and-the-feynman-technique</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/learn-anything-with-ai-and-the-feynman-technique/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[study any concept in four easy steps, by applying AI and a Noble Prize winner approachContinue reading on Towards AI »]]></summary></entry><entry><title type="html">A Comprehensive Guide to Collaborative AI Agents in Practice</title><link href="https://hesamsheikh.github.io/blog/2024/a-comprehensive-guide-to-collaborative-ai-agents-in-practice/" rel="alternate" type="text/html" title="A Comprehensive Guide to Collaborative AI Agents in Practice"/><published>2024-07-03T18:48:15+00:00</published><updated>2024-07-03T18:48:15+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/a-comprehensive-guide-to-collaborative-ai-agents-in-practice</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/a-comprehensive-guide-to-collaborative-ai-agents-in-practice/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[the definition, and building a team of agents that refine your CV and Cover Letter for job applicationsContinue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Why Medium is the Easiest Way to Start Up Your Personal Brand in 2024</title><link href="https://hesamsheikh.github.io/blog/2024/why-medium-is-the-easiest-way-to-start-up-your-personal-brand-in-2024/" rel="alternate" type="text/html" title="Why Medium is the Easiest Way to Start Up Your Personal Brand in 2024"/><published>2024-07-01T15:32:36+00:00</published><updated>2024-07-01T15:32:36+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/why-medium-is-the-easiest-way-to-start-up-your-personal-brand-in-2024</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/why-medium-is-the-easiest-way-to-start-up-your-personal-brand-in-2024/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[It&#x2019;s not too late to grow your brand and start your one-person business on Medium.Continue reading on Medium »]]></summary></entry><entry><title type="html">Understanding Buffer of Thoughts (BoT) — Reasoning with Large Language Models</title><link href="https://hesamsheikh.github.io/blog/2024/understanding-buffer-of-thoughts-botreasoning-with-large-language-models/" rel="alternate" type="text/html" title="Understanding Buffer of Thoughts (BoT) — Reasoning with Large Language Models"/><published>2024-06-14T23:21:57+00:00</published><updated>2024-06-14T23:21:57+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/understanding-buffer-of-thoughts-botreasoning-with-large-language-models</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/understanding-buffer-of-thoughts-botreasoning-with-large-language-models/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[New prompt engineering tool for complex reasoning, compared with Chain of thought (CoT) and Tree of Thought (ToT)Continue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Understanding MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning</title><link href="https://hesamsheikh.github.io/blog/2024/understanding-mora-high-rank-updating-for-parameter-efficient-fine-tuning/" rel="alternate" type="text/html" title="Understanding MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning"/><published>2024-06-07T12:02:12+00:00</published><updated>2024-06-07T12:02:12+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/understanding-mora-high-rank-updating-for-parameter-efficient-fine-tuning</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/understanding-mora-high-rank-updating-for-parameter-efficient-fine-tuning/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[the math and intuition behind a novel parameter-efficient fine-tuning methodContinue reading on Towards AI »]]></summary></entry><entry><title type="html">LoRA Learns Less and Forgets Less</title><link href="https://hesamsheikh.github.io/blog/2024/lora-learns-less-and-forgets-less/" rel="alternate" type="text/html" title="LoRA Learns Less and Forgets Less"/><published>2024-06-07T00:02:15+00:00</published><updated>2024-06-07T00:02:15+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/lora-learns-less-and-forgets-less</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/lora-learns-less-and-forgets-less/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We will go through LoRA (Low-Rank Adaptation of Large Language Models), and compare LoRA to Full Fine-Tuning.Continue reading on Towards AI »]]></summary></entry><entry><title type="html">Build Your First AI Agent in 5 Easy Steps (100% local)</title><link href="https://hesamsheikh.github.io/blog/2024/build-your-first-ai-agent-in-5-easy-steps-100-local/" rel="alternate" type="text/html" title="Build Your First AI Agent in 5 Easy Steps (100% local)"/><published>2024-05-31T14:02:31+00:00</published><updated>2024-05-31T14:02:31+00:00</updated><id>https://hesamsheikh.github.io/blog/2024/build-your-first-ai-agent-in-5-easy-steps-100-local</id><content type="html" xml:base="https://hesamsheikh.github.io/blog/2024/build-your-first-ai-agent-in-5-easy-steps-100-local/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Creating AI agents with Crewai and using Ollama to run them 100% locally in 5 very easy steps!Continue reading on Towards AI »]]></summary></entry></feed>